{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"Hey, I am aditya. I am learning NLP right now.\n",
    "I started with basics of python and then jumped to ML for NLP.\n",
    "ultimate goal is to learn Gen AI and Agentic AI.\n",
    "However I need to do one ML project as an add on for the house pricing dataset following the roadmap.txt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, I am aditya. I am learning NLP right now.\n",
      "I started with basics of python and then jumped to ML for NLP.\n",
      "ultimate goal is to learn Gen AI and Agentic AI.\n",
      "However I need to do one ML project as an add on for the house pricing dataset following the roadmap.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text preprocessing \n",
    "## first way to process is using tokenization using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import *\n",
    "#import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey, I am aditya.',\n",
       " 'I am learning NLP right now.',\n",
       " 'I started with basics of python and then jumped to ML for NLP.',\n",
       " 'ultimate goal is to learn Gen AI and Agentic AI.',\n",
       " 'However I need to do one ML project as an add on for the house pricing dataset following the roadmap.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.tokenize.sent_tokenize(corpus)\n",
    "sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey',\n",
       " ',',\n",
       " 'I',\n",
       " 'am',\n",
       " 'aditya',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'learning',\n",
       " 'NLP',\n",
       " 'right',\n",
       " 'now',\n",
       " '.',\n",
       " 'I',\n",
       " 'started',\n",
       " 'with',\n",
       " 'basics',\n",
       " 'of',\n",
       " 'python',\n",
       " 'and',\n",
       " 'then',\n",
       " 'jumped',\n",
       " 'to',\n",
       " 'ML',\n",
       " 'for',\n",
       " 'NLP',\n",
       " '.',\n",
       " 'ultimate',\n",
       " 'goal',\n",
       " 'is',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'Gen',\n",
       " 'AI',\n",
       " 'and',\n",
       " 'Agentic',\n",
       " 'AI',\n",
       " '.',\n",
       " 'However',\n",
       " 'I',\n",
       " 'need',\n",
       " 'to',\n",
       " 'do',\n",
       " 'one',\n",
       " 'ML',\n",
       " 'project',\n",
       " 'as',\n",
       " 'an',\n",
       " 'add',\n",
       " 'on',\n",
       " 'for',\n",
       " 'the',\n",
       " 'house',\n",
       " 'pricing',\n",
       " 'dataset',\n",
       " 'following',\n",
       " 'the',\n",
       " 'roadmap.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word tokenize\n",
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we have other tokenizer methods as well but generally we use these two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another way to preprocess is Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[\"eat\",\"eating\",\"eaten\",\"write\",\"writing\",\"written\",\"history\",\"finally\",\"final\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer as PS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming=PS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat---->eat\n",
      "eating---->eat\n",
      "eaten---->eaten\n",
      "write---->write\n",
      "writing---->write\n",
      "written---->written\n",
      "history---->histori\n",
      "finally---->final\n",
      "final---->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"---->\" + stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## when stemming is applied sometimes it doesnt give correct output forexample \"history\" is \"histori\"\n",
    "PS().stem(\"congratulations\")\n",
    "# we can use other stemming apart from porter stemming to improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegexpStemmer Class\n",
    "#### takes a single regex and removes any prefix suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer=RegexpStemmer(\"ing$|s$|e$|able$\",min=4) #removes last ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat---->eat\n",
      "eating---->eat\n",
      "eaten---->eaten\n",
      "write---->writ\n",
      "writing---->writ\n",
      "written---->written\n",
      "history---->history\n",
      "finally---->finally\n",
      "final---->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"---->\" + reg_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### snowball stemmer\n",
    "#### better than porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat---->eat\n",
      "eating---->eat\n",
      "eaten---->eaten\n",
      "write---->write\n",
      "writing---->write\n",
      "written---->written\n",
      "history---->histori\n",
      "finally---->final\n",
      "final---->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"---->\" + snowball.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### snowball is better in many cases as compared to potter yet its not best and gives somebad words so its not good for chatbots etc. So we go for other way like LEMMAIZATION as it has dictionary or vacabulary of all words so good at grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lemmatization is like stemming. OP -> is called \"lemma\" but gives better output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### noun->n verb->v adjective->a adverb->r\n",
    "### pos is parts of speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"going\",pos=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat---->eat\n",
      "eating---->eat\n",
      "eaten---->eat\n",
      "write---->write\n",
      "writing---->write\n",
      "written---->write\n",
      "history---->history\n",
      "finally---->finally\n",
      "final---->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \"---->\" + lemmatizer.lemmatize(word,pos=\"v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###lemmatizer is betterr but it takes more time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"\"\"I have a dream that one day down in Alabama, with its vicious racists, with its governor having his lips dripping with the words of interposition and nullification – one day right there in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers.\n",
    "I have a dream today. I have a dream that one day every valley shall be exalted, and every hill and mountain shall be made low, the rough places will be made plain, and the crooked places will be made straight, and the glory of the Lord shall be revealed and all flesh shall see it together.\n",
    "\n",
    "This is our hope. This is the faith that I go back to the South with. With this faith we will be able to hew out of the mountain of despair a stone of hope. With this faith we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood. With this faith we will be able to work together, to pray together, to struggle together, to go to jail together, to stand up for freedom together, knowing that we will be free one day.\n",
    "\n",
    "This will be the day, this will be the day when all of God’s children will be able to sing with new meaning “My country ’tis of thee, sweet land of liberty, of thee I sing. Land where my father’s died, land of the Pilgrim’s pride, from every mountainside, let freedom ring!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a dream that one day down in Alabama, with its vicious racists, with its governor having his lips dripping with the words of interposition and nullification – one day right there in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers.\n",
      "I have a dream today. I have a dream that one day every valley shall be exalted, and every hill and mountain shall be made low, the rough places will be made plain, and the crooked places will be made straight, and the glory of the Lord shall be revealed and all flesh shall see it together.\n",
      "\n",
      "This is our hope. This is the faith that I go back to the South with. With this faith we will be able to hew out of the mountain of despair a stone of hope. With this faith we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood. With this faith we will be able to work together, to pray together, to struggle together, to go to jail together, to stand up for freedom together, knowing that we will be free one day.\n",
      "\n",
      "This will be the day, this will be the day when all of God’s children will be able to sing with new meaning “My country ’tis of thee, sweet land of liberty, of thee I sing. Land where my father’s died, land of the Pilgrim’s pride, from every mountainside, let freedom ring!\n"
     ]
    }
   ],
   "source": [
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\") #checking the stopwords (which are not useful or add much importance while detecting spams) in english \n",
    "#best thing is to create your own stop words (a list ) as the default has many which might be useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()\n",
    "sentences=sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply stop words and then filter based on if it falls in category of stop words. And then apply stemming on sentences which we already created(tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):     #iterate through each sentence\n",
    "    words=word_tokenize(sentences[i])      #tokenize each sentence (get a lsit of words)\n",
    "    words=[stemmer.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]  #list of words after filtering\n",
    "    sentences[i]=\" \".join(words)    #convert all words into sentences back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i dream one day alabama , viciou racist , governor lip drip word interposit nullif – one day right alabama littl black boy black girl abl join hand littl white boy white girl sister brother .', 'i dream today .', 'i dream one day everi valley shall exalt , everi hill mountain shall made low , rough place made plain , crook place made straight , glori lord shall reveal flesh shall see togeth .', 'thi hope .', 'thi faith i go back south .', 'with faith abl hew mountain despair stone hope .', 'with faith abl transform jangl discord nation beauti symphoni brotherhood .', 'with faith abl work togeth , pray togeth , struggl togeth , go jail togeth , stand freedom togeth , know free one day .', 'thi day , day god ’ children abl sing new mean “ my countri ’ ti thee , sweet land liberti , thee i sing .', 'land father ’ die , land pilgrim ’ pride , everi mountainsid , let freedom ring !']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"\"\"I have a dream that one day down in Alabama, with its vicious racists, with its governor having his lips dripping with the words of interposition and nullification – one day right there in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers.\n",
    "I have a dream today. I have a dream that one day every valley shall be exalted, and every hill and mountain shall be made low, the rough places will be made plain, and the crooked places will be made straight, and the glory of the Lord shall be revealed and all flesh shall see it together.\n",
    "\n",
    "This is our hope. This is the faith that I go back to the South with. With this faith we will be able to hew out of the mountain of despair a stone of hope. With this faith we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood. With this faith we will be able to work together, to pray together, to struggle together, to go to jail together, to stand up for freedom together, knowing that we will be free one day.\n",
    "\n",
    "This will be the day, this will be the day when all of God’s children will be able to sing with new meaning “My country ’tis of thee, sweet land of liberty, of thee I sing. Land where my father’s died, land of the Pilgrim’s pride, from every mountainside, let freedom ring!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply snow ball\n",
    "sentences=sent_tokenize(paragraph)\n",
    "for i in range(len(sentences)):     #iterate through each sentence\n",
    "    words=word_tokenize(sentences[i])      #tokenize each sentence (get a lsit of words)\n",
    "    words=[snowball.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]  #list of words after filtering\n",
    "    sentences[i]=\" \".join(words)    #convert all words into sentences back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i dream one day alabama , vicious racist , governor lip drip word interposit nullif – one day right alabama littl black boy black girl abl join hand littl white boy white girl sister brother .', 'i dream today .', 'i dream one day everi valley shall exalt , everi hill mountain shall made low , rough place made plain , crook place made straight , glori lord shall reveal flesh shall see togeth .', 'this hope .', 'this faith i go back south .', 'with faith abl hew mountain despair stone hope .', 'with faith abl transform jangl discord nation beauti symphoni brotherhood .', 'with faith abl work togeth , pray togeth , struggl togeth , go jail togeth , stand freedom togeth , know free one day .', 'this day , day god ’ children abl sing new mean “ my countri ’ tis thee , sweet land liberti , thee i sing .', 'land father ’ die , land pilgrim ’ pride , everi mountainsid , let freedom ring !']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply lemmatizer\n",
    "paragraph=\"\"\"I have a dream that one day down in Alabama, with its vicious racists, with its governor having his lips dripping with the words of interposition and nullification – one day right there in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers.\n",
    "I have a dream today. I have a dream that one day every valley shall be exalted, and every hill and mountain shall be made low, the rough places will be made plain, and the crooked places will be made straight, and the glory of the Lord shall be revealed and all flesh shall see it together.\n",
    "\n",
    "This is our hope. This is the faith that I go back to the South with. With this faith we will be able to hew out of the mountain of despair a stone of hope. With this faith we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood. With this faith we will be able to work together, to pray together, to struggle together, to go to jail together, to stand up for freedom together, knowing that we will be free one day.\n",
    "\n",
    "This will be the day, this will be the day when all of God’s children will be able to sing with new meaning “My country ’tis of thee, sweet land of liberty, of thee I sing. Land where my father’s died, land of the Pilgrim’s pride, from every mountainside, let freedom ring!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply snow ball\n",
    "sentences=sent_tokenize(paragraph)\n",
    "for i in range(len(sentences)):     #iterate through each sentence\n",
    "    words=word_tokenize(sentences[i])      #tokenize each sentence (get a lsit of words)\n",
    "    words=[lemmatizer.lemmatize(word,pos=\"v\") for word in words if word not in set(stopwords.words(\"english\"))]  #list of words after filtering\n",
    "    sentences[i]=\" \".join(words)    #convert all words into sentences back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I dream one day Alabama , vicious racists , governor lips drip word interposition nullification – one day right Alabama little black boys black girls able join hand little white boys white girls sisters brothers .', 'I dream today .', 'I dream one day every valley shall exalt , every hill mountain shall make low , rough place make plain , crook place make straight , glory Lord shall reveal flesh shall see together .', 'This hope .', 'This faith I go back South .', 'With faith able hew mountain despair stone hope .', 'With faith able transform jangle discord nation beautiful symphony brotherhood .', 'With faith able work together , pray together , struggle together , go jail together , stand freedom together , know free one day .', 'This day , day God ’ children able sing new mean “ My country ’ tis thee , sweet land liberty , thee I sing .', 'Land father ’ die , land Pilgrim ’ pride , every mountainside , let freedom ring !']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
