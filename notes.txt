Purpose Of This Notes:

I started to Learn Agentic AI and I believe it would be great if I start from the basics(python) and go to advance level(LLM models) and cover all topics and prepare short notes/ Roadmap which I can refer later.

Installed so far:

python extension by microsoft.
anaconda from official website.

################################################################################## 
Ways of creating python Environment:
Need: If working on multiple projects and multiple apps, you need to have different versions of python or any other dependency. You can easily achieve it by creating different venv(virtual environments).
command 1:  python -m venv myenv
activate the environment: myenv\Scripts\activate
command 2(anaconda should be installed): conda create -p venv python==3.12 -y 
activate : conda activate venv/

Note: (remove env while pushing code to git) 
better create a requirements.txt file and run it to install any library or dependency
command : pip install -r requirements.txt
##################################################################################

##################################################################################
Basics Of Python:
1.case sensitive.
2.Indentation.
3.Multi statement in single line supported.
4.Data types auto assigned.
refer to the ipynb file. (01-python-basics.ipynb)
##################################################################################

##################################################################################
DS in Python (list,tuple,set and Dict):
1. List is ordered, mutable and can have different datatypes  ---> []
2. Tuples are ordered but immutable----> ()
3. Dict are unordered in key(unique and immuatable) value(mutable) pair ---> {}
##################################################################################

##################################################################################
Functions in python
1. Functions with arguments
2. positional and keyword arguments
3. lambda funtions (anonymous functions== without name)(any number of arguments but one expression)
4. map functions  (applies a particular function to all elements in a list)
5. filter functions (filter elements in a collection based on condition)
##################################################################################

##################################################################################
OOPS in python:
1. Class and Objects
2. Inheritance
3. Polymorphism
4. Encapsulation and Abstraction
5. Operator Overloading(Pending)
##################################################################################

##################################################################################
Pending Topic (File handling in python and Exception handling)
Advanced Python is still pending
##################################################################################

[Note: Some Advanced topic are skipped but can be done after learning and implementing GenAI and Agentic AI ]

##################################################################################
StreamLit: App framework (Good for creating webapps for Data Science and ML projects)
cd 05-streamlit-demo  -->change directory in which app is present
streamlit run app.py  -->run this command "give full app location"
##################################################################################

##################################################################################
Basics Of ML and Project Roadmap : refer to the roadmap.txt
[important to learn few library like panda,numpy,sklearn,matplot lib ]
ML for NLP: (data-->preprocess-->vectors-->ML model/DL model)
1. Text preprocessing:
a. Tokenization: (Download nltk library and its data(4 gb) will delete in future so you need to download again)
tokenization is the process of breaking down text into smaller units called tokens. These tokens can be words, phrases, or even individual characters.
corpus = paragraph
documents = sentences
vocabulary = unique words
words = words
b. stemming: way of reducing a word to its stem (remove prefix suffix etc)
example [eating,eat,eaten] ---> [eat]
        [going,gone,go]    ---> [go]
c. Lemmatization: its just like stemming but much better as it uses Dictionary and supports multiple languages
d. StopWords: "words which dont add much meaning in the model so we filter them or remove using stopwords"
e. POS tagging: tag parts of speech and classify them as noun pronouns etc
f. Named Entity Recognition: gives a detailed classification and graph too.  It's a step beyond POS tagging, grouping words into larger grammatical units.

2. Text to vectors:
(Accuracy and performance gets better as we go down with new approaches)
a. One Hot Encoding: Not a good approach here for NLP use case(applied on all words so create vectors for each word-> 2d maatrix). Lost of disadvantages like overfitting, Out of vocabulary, inconsistent data size.
b. Bag of words (bow): i/p data size is consistent yet many disadvatages (here it applies on a sentence so its more like 1d).
c. N-grams (can be used with upper methods too): eg bi-gram tri-gram we try to create new words by combining words like creating new feature/column for the maatrix
    * sklearn -> n-grams=(1,1) "unigrams"
              -> n-grams=(1,3) "uni,bi,tri"
              -> n-grams=(2,3) "bi,tri"
d. TF-IDF:term freq - inverse documents freq
    * word importance is captured

e. Word2Vec : works like feature representation of each word(vocab) which is used to create vectors
    i.CBOW -> small dataset
    ii.Skipgram -> big data set

##################################################################################

##################################################################################
DL for NLP
1. ANN
2. RNN 
3. CNN 
##################################################################################







